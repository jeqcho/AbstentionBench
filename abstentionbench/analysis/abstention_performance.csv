model_name_formatted,scenario_label,dataset_name_formatted,post_training_stage,precision,recall,f1_score
DeepSeek R1 Distill Llama 70B,answer unknown,BB/Known unknowns,NA,0.9333333333333333,0.6086956521739131,0.7368421052631579
DeepSeek R1 Distill Llama 70B,answer unknown,CoCoNot/Unknowns,NA,1.0,0.7761194029850746,0.8739495798319328
DeepSeek R1 Distill Llama 70B,answer unknown,CoCoNot/Unsupported,NA,1.0,0.6416666666666667,0.7817258883248731
DeepSeek R1 Distill Llama 70B,answer unknown,KUQ/Future unknowns,NA,0.9725274725274725,0.5429447852760736,0.6968503937007874
DeepSeek R1 Distill Llama 70B,answer unknown,KUQ/Unsolved problems,NA,0.9375,0.5106382978723404,0.6611570247933884
DeepSeek R1 Distill Llama 70B,false premise,CoCoNot/False presumptions,NA,0.9821428571428571,0.6626506024096386,0.7913669064748201
DeepSeek R1 Distill Llama 70B,false premise,FalseQA,NA,0.9363057324840764,0.4279475982532751,0.5874125874125874
DeepSeek R1 Distill Llama 70B,false premise,KUQ/False assumptions,NA,0.9618320610687023,0.47368421052631576,0.6347607052896725
DeepSeek R1 Distill Llama 70B,false premise,QAQA,NA,0.9285714285714286,0.3192982456140351,0.4751958224543081
DeepSeek R1 Distill Llama 70B,stale,CoCoNot/Temporal,NA,1.0,0.5135135135135135,0.6785714285714286
DeepSeek R1 Distill Llama 70B,stale,FreshQA,NA,0.45454545454545453,0.3191489361702128,0.375
DeepSeek R1 Distill Llama 70B,subjective,CoCoNot/Humanizing,NA,1.0,0.6341463414634146,0.7761194029850746
DeepSeek R1 Distill Llama 70B,subjective,CoCoNot/Subjective,NA,1.0,0.22666666666666666,0.3695652173913043
DeepSeek R1 Distill Llama 70B,subjective,KUQ/Controversial,NA,0.9659863945578231,0.42136498516320475,0.5867768595041323
DeepSeek R1 Distill Llama 70B,subjective,MoralChoice,NA,1.0,0.225,0.3673469387755102
DeepSeek R1 Distill Llama 70B,underspecified context,ALCUNA,NA,0.9167367535744323,0.6293302540415704,0.7463197535090722
DeepSeek R1 Distill Llama 70B,underspecified context,BB/Disambiguate,NA,0.5405405405405406,0.26666666666666666,0.35714285714285715
DeepSeek R1 Distill Llama 70B,underspecified context,BBQ,NA,0.9859278803869833,0.6304836895388076,0.7691252144082332
DeepSeek R1 Distill Llama 70B,underspecified context,GPQA-Diamond,NA,0.8333333333333334,0.25,0.38461538461538464
DeepSeek R1 Distill Llama 70B,underspecified context,GSM8K,NA,0.9895470383275261,0.4682605111294312,0.6357022943480694
DeepSeek R1 Distill Llama 70B,underspecified context,MMLU History,NA,0.6666666666666666,0.05128205128205128,0.09523809523809523
DeepSeek R1 Distill Llama 70B,underspecified context,MMLU Math,NA,0.9183673469387755,0.3383458646616541,0.4945054945054945
DeepSeek R1 Distill Llama 70B,underspecified context,MediQ,NA,0.9622641509433962,0.0361958836053939,0.06976744186046512
DeepSeek R1 Distill Llama 70B,underspecified context,Musique,NA,0.8866171003717472,0.36246200607902734,0.5145631067961165
DeepSeek R1 Distill Llama 70B,underspecified context,QASPER,NA,0.2647058823529412,0.9113924050632911,0.41025641025641024
DeepSeek R1 Distill Llama 70B,underspecified context,SQuAD 2.0,NA,0.9839080459770115,0.48334274421230944,0.6482393032942068
DeepSeek R1 Distill Llama 70B,underspecified context,UMWP,NA,0.9959839357429718,0.5668571428571428,0.7225054624908959
DeepSeek R1 Distill Llama 70B,underspecified context,WorldSense,NA,0.8618219037871033,0.9745370370370371,0.9147202607278653
DeepSeek R1 Distill Llama 70B,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.6122448979591837,0.759493670886076
DeepSeek R1 Distill Llama 70B,underspecified intent,KUQ/Ambiguous,NA,0.8263473053892215,0.45695364238410596,0.5884861407249466
DeepSeek R1 Distill Llama 70B,underspecified intent,SituatedQA/Geo,NA,0.8620689655172413,0.3875968992248062,0.5347593582887701
GPT-4o,answer unknown,BB/Known unknowns,NA,1.0,0.9565217391304348,0.9777777777777777
GPT-4o,answer unknown,CoCoNot/Unknowns,NA,1.0,0.9850746268656716,0.9924812030075187
GPT-4o,answer unknown,CoCoNot/Unsupported,NA,0.990990990990991,0.9166666666666666,0.9523809523809523
GPT-4o,answer unknown,KUQ/Future unknowns,NA,0.90625,0.7116564417177914,0.7972508591065293
GPT-4o,answer unknown,KUQ/Unsolved problems,NA,0.8795811518324608,0.7148936170212766,0.7887323943661971
GPT-4o,false premise,CoCoNot/False presumptions,NA,0.96875,0.7469879518072289,0.8435374149659864
GPT-4o,false premise,FalseQA,NA,0.9059080962800875,0.6026200873362445,0.7237762237762237
GPT-4o,false premise,KUQ/False assumptions,NA,0.9121951219512195,0.7030075187969925,0.7940552016985138
GPT-4o,false premise,QAQA,NA,0.9221556886227545,0.5403508771929825,0.6814159292035398
GPT-4o,stale,CoCoNot/Temporal,NA,1.0,0.7837837837837838,0.8787878787878788
GPT-4o,stale,FreshQA,NA,0.46,0.48936170212765956,0.4742268041237113
GPT-4o,subjective,CoCoNot/Humanizing,NA,1.0,0.8902439024390244,0.9419354838709677
GPT-4o,subjective,CoCoNot/Subjective,NA,1.0,0.7866666666666666,0.8805970149253731
GPT-4o,subjective,KUQ/Controversial,NA,0.9080459770114943,0.7032640949554896,0.7926421404682275
GPT-4o,subjective,MoralChoice,NA,0.9834254143646409,0.26176470588235295,0.413472706155633
GPT-4o,underspecified context,ALCUNA,NA,0.8549668874172185,0.7453810623556582,0.796421961752005
GPT-4o,underspecified context,BB/Disambiguate,NA,0.3544973544973545,0.8933333333333333,0.5075757575757576
GPT-4o,underspecified context,BBQ,NA,0.9406580493537016,0.9004499437570304,0.9201149425287356
GPT-4o,underspecified context,GPQA-Diamond,NA,1.0,0.75,0.8571428571428571
GPT-4o,underspecified context,GSM8K,NA,1.0,0.920032976092333,0.9583512237011593
GPT-4o,underspecified context,MMLU History,NA,1.0,0.5128205128205128,0.6779661016949152
GPT-4o,underspecified context,MMLU Math,NA,0.9693877551020408,0.7142857142857143,0.8225108225108225
GPT-4o,underspecified context,MediQ,NA,0.993920972644377,0.2320794889992903,0.3762945914844649
GPT-4o,underspecified context,Musique,NA,0.9167591564927858,0.6276595744680851,0.7451511050969779
GPT-4o,underspecified context,QASPER,NA,0.2367601246105919,0.9620253164556962,0.38
GPT-4o,underspecified context,SQuAD 2.0,NA,0.9836538461538461,0.577639751552795,0.727854855923159
GPT-4o,underspecified context,UMWP,NA,0.9974160206718347,0.6617142857142857,0.7956028856063209
GPT-4o,underspecified context,WorldSense,NA,0.8482658959537572,0.6793981481481481,0.7544987146529563
GPT-4o,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.9387755102040817,0.968421052631579
GPT-4o,underspecified intent,KUQ/Ambiguous,NA,0.7762711864406779,0.7582781456953642,0.7671691792294807
GPT-4o,underspecified intent,SituatedQA/Geo,NA,0.6992481203007519,0.7209302325581395,0.7099236641221374
Gemini 1.5 Pro,answer unknown,BB/Known unknowns,NA,0.9583333333333334,1.0,0.9787234042553191
Gemini 1.5 Pro,answer unknown,CoCoNot/Unknowns,NA,1.0,0.9701492537313433,0.9848484848484849
Gemini 1.5 Pro,answer unknown,CoCoNot/Unsupported,NA,0.9741379310344828,0.9416666666666667,0.9576271186440678
Gemini 1.5 Pro,answer unknown,KUQ/Future unknowns,NA,0.8916967509025271,0.7576687116564417,0.8192371475953566
Gemini 1.5 Pro,answer unknown,KUQ/Unsolved problems,NA,0.883495145631068,0.774468085106383,0.8253968253968254
Gemini 1.5 Pro,false premise,CoCoNot/False presumptions,NA,0.90625,0.6987951807228916,0.7891156462585034
Gemini 1.5 Pro,false premise,FalseQA,NA,0.8345070422535211,0.6899563318777293,0.7553784860557768
Gemini 1.5 Pro,false premise,KUQ/False assumptions,NA,0.9230769230769231,0.6766917293233082,0.7809110629067245
Gemini 1.5 Pro,false premise,QAQA,NA,0.8385416666666666,0.5649122807017544,0.6750524109014675
Gemini 1.5 Pro,stale,CoCoNot/Temporal,NA,1.0,0.5945945945945946,0.7457627118644068
Gemini 1.5 Pro,stale,FreshQA,NA,0.5151515151515151,0.3617021276595745,0.425
Gemini 1.5 Pro,subjective,CoCoNot/Humanizing,NA,1.0,0.8902439024390244,0.9419354838709677
Gemini 1.5 Pro,subjective,CoCoNot/Subjective,NA,1.0,0.8133333333333334,0.8970588235294118
Gemini 1.5 Pro,subjective,KUQ/Controversial,NA,0.8668941979522184,0.7537091988130564,0.8063492063492064
Gemini 1.5 Pro,subjective,MoralChoice,NA,0.9763313609467456,0.2426470588235294,0.38869257950530034
Gemini 1.5 Pro,underspecified context,ALCUNA,NA,0.8953568953568953,0.745958429561201,0.8138582677165355
Gemini 1.5 Pro,underspecified context,BB/Disambiguate,NA,0.3974358974358974,0.8266666666666667,0.5367965367965368
Gemini 1.5 Pro,underspecified context,BBQ,NA,0.918903803131991,0.9240719910011248,0.9214806505888952
Gemini 1.5 Pro,underspecified context,GPQA-Diamond,NA,0.9523809523809523,0.5,0.6557377049180327
Gemini 1.5 Pro,underspecified context,GSM8K,NA,0.9991258741258742,0.9422918384171476,0.9698769622401358
Gemini 1.5 Pro,underspecified context,MMLU History,NA,0.92,0.5897435897435898,0.71875
Gemini 1.5 Pro,underspecified context,MMLU Math,NA,1.0,0.5112781954887218,0.6766169154228856
Gemini 1.5 Pro,underspecified context,MediQ,NA,0.9861878453038674,0.25337118523775726,0.4031620553359684
Gemini 1.5 Pro,underspecified context,Musique,NA,0.8098747236551216,0.8351063829787234,0.8222970445192668
Gemini 1.5 Pro,underspecified context,QASPER,NA,0.21487603305785125,0.9873417721518988,0.35294117647058826
Gemini 1.5 Pro,underspecified context,SQuAD 2.0,NA,0.9849690539345711,0.6290231507622812,0.7677463818056512
Gemini 1.5 Pro,underspecified context,UMWP,NA,0.9867768595041322,0.6822857142857143,0.8067567567567567
Gemini 1.5 Pro,underspecified context,WorldSense,NA,0.8580508474576272,0.46875,0.6062874251497006
Gemini 1.5 Pro,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.8979591836734694,0.946236559139785
Gemini 1.5 Pro,underspecified intent,KUQ/Ambiguous,NA,0.742671009771987,0.7549668874172185,0.7487684729064039
Gemini 1.5 Pro,underspecified intent,SituatedQA/Geo,NA,0.5035460992907801,0.5503875968992248,0.5259259259259259
Llama 3.1 405B Instruct,answer unknown,BB/Known unknowns,NA,0.92,1.0,0.9583333333333334
Llama 3.1 405B Instruct,answer unknown,CoCoNot/Unknowns,NA,1.0,1.0,1.0
Llama 3.1 405B Instruct,answer unknown,CoCoNot/Unsupported,NA,0.9813084112149533,0.875,0.9251101321585903
Llama 3.1 405B Instruct,answer unknown,KUQ/Future unknowns,NA,0.8623481781376519,0.6533742331288344,0.743455497382199
Llama 3.1 405B Instruct,answer unknown,KUQ/Unsolved problems,NA,0.8333333333333334,0.6382978723404256,0.7228915662650602
Llama 3.1 405B Instruct,false premise,CoCoNot/False presumptions,NA,0.88,0.7951807228915663,0.8354430379746836
Llama 3.1 405B Instruct,false premise,FalseQA,NA,0.8625277161862528,0.5662299854439592,0.6836555360281195
Llama 3.1 405B Instruct,false premise,KUQ/False assumptions,NA,0.835,0.6278195488721805,0.7167381974248928
Llama 3.1 405B Instruct,false premise,QAQA,NA,0.8461538461538461,0.5017543859649123,0.6299559471365639
Llama 3.1 405B Instruct,stale,CoCoNot/Temporal,NA,1.0,0.7567567567567568,0.8615384615384616
Llama 3.1 405B Instruct,stale,FreshQA,NA,0.2982456140350877,0.723404255319149,0.422360248447205
Llama 3.1 405B Instruct,subjective,CoCoNot/Humanizing,NA,1.0,0.8902439024390244,0.9419354838709677
Llama 3.1 405B Instruct,subjective,CoCoNot/Subjective,NA,1.0,0.7333333333333333,0.8461538461538461
Llama 3.1 405B Instruct,subjective,KUQ/Controversial,NA,0.8852459016393442,0.6409495548961425,0.7435456110154905
Llama 3.1 405B Instruct,subjective,MoralChoice,NA,0.9845360824742269,0.28088235294117647,0.43707093821510296
Llama 3.1 405B Instruct,underspecified context,ALCUNA,NA,0.9327217125382263,0.7043879907621247,0.8026315789473685
Llama 3.1 405B Instruct,underspecified context,BB/Disambiguate,NA,0.4852941176470588,0.88,0.6255924170616114
Llama 3.1 405B Instruct,underspecified context,BBQ,NA,0.9649546827794562,0.8982002249718786,0.9303815904456744
Llama 3.1 405B Instruct,underspecified context,GPQA-Diamond,NA,1.0,0.65,0.7878787878787878
Llama 3.1 405B Instruct,underspecified context,GSM8K,NA,0.9965457685664939,0.9513602638087386,0.9734289329396879
Llama 3.1 405B Instruct,underspecified context,MMLU History,NA,0.8125,0.3333333333333333,0.4727272727272727
Llama 3.1 405B Instruct,underspecified context,MMLU Math,NA,1.0,0.6917293233082706,0.8177777777777778
Llama 3.1 405B Instruct,underspecified context,MediQ,NA,0.9935483870967742,0.21859474804826118,0.358347876672484
Llama 3.1 405B Instruct,underspecified context,Musique,NA,0.8940864960282436,0.7697568389057751,0.8272764393630053
Llama 3.1 405B Instruct,underspecified context,QASPER,NA,0.25,0.9620253164556962,0.3968668407310705
Llama 3.1 405B Instruct,underspecified context,SQuAD 2.0,NA,0.9708520179372198,0.7334839073969509,0.8356384689610807
Llama 3.1 405B Instruct,underspecified context,WorldSense,NA,0.8748114630467572,0.6712962962962963,0.7596594629993452
Llama 3.1 405B Instruct,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.8571428571428571,0.9230769230769231
Llama 3.1 405B Instruct,underspecified intent,KUQ/Ambiguous,NA,0.6285714285714286,0.6556291390728477,0.6418152350081038
Llama 3.1 405B Instruct,underspecified intent,SituatedQA/Geo,NA,0.4967741935483871,0.5968992248062015,0.5422535211267606
Llama 3.1 70B Base,answer unknown,BB/Known unknowns,Base,0.8333333333333334,0.43478260869565216,0.5714285714285714
Llama 3.1 70B Base,answer unknown,CoCoNot/Unknowns,Base,1.0,0.6417910447761194,0.7818181818181819
Llama 3.1 70B Base,answer unknown,CoCoNot/Unsupported,Base,0.8309859154929577,0.49166666666666664,0.6178010471204188
Llama 3.1 70B Base,answer unknown,KUQ/Future unknowns,Base,0.9081081081081082,0.5153374233128835,0.6575342465753424
Llama 3.1 70B Base,answer unknown,KUQ/Unsolved problems,Base,0.8450704225352113,0.5106382978723404,0.636604774535809
Llama 3.1 70B Base,false premise,CoCoNot/False presumptions,Base,0.75,0.2891566265060241,0.41739130434782606
Llama 3.1 70B Base,false premise,FalseQA,Base,0.6880733944954128,0.2183406113537118,0.3314917127071823
Llama 3.1 70B Base,false premise,KUQ/False assumptions,Base,0.8913043478260869,0.462406015037594,0.6089108910891089
Llama 3.1 70B Base,false premise,QAQA,Base,0.7522935779816514,0.28771929824561404,0.41624365482233505
Llama 3.1 70B Base,stale,CoCoNot/Temporal,Base,1.0,0.43243243243243246,0.6037735849056604
Llama 3.1 70B Base,stale,FreshQA,Base,0.625,0.425531914893617,0.5063291139240507
Llama 3.1 70B Base,subjective,CoCoNot/Humanizing,Base,1.0,0.4634146341463415,0.6333333333333333
Llama 3.1 70B Base,subjective,CoCoNot/Subjective,Base,1.0,0.6133333333333333,0.7603305785123967
Llama 3.1 70B Base,subjective,KUQ/Controversial,Base,0.8888888888888888,0.45103857566765576,0.5984251968503937
Llama 3.1 70B Base,subjective,MoralChoice,Base,0.5611510791366906,0.5735294117647058,0.5672727272727273
Llama 3.1 70B Base,underspecified context,ALCUNA,Base,0.7306338028169014,0.7188221709006929,0.7246798603026775
Llama 3.1 70B Base,underspecified context,BB/Disambiguate,Base,0.5267175572519084,0.92,0.6699029126213593
Llama 3.1 70B Base,underspecified context,BBQ,Base,0.9328018223234624,0.46062992125984253,0.6167168674698795
Llama 3.1 70B Base,underspecified context,GPQA-Diamond,Base,0.9,0.225,0.36
Llama 3.1 70B Base,underspecified context,GSM8K,Base,0.8096676737160121,0.22093981863149217,0.3471502590673575
Llama 3.1 70B Base,underspecified context,MMLU History,Base,1.0,0.02564102564102564,0.05
Llama 3.1 70B Base,underspecified context,MediQ,Base,0.990909090909091,0.0773598296664301,0.14351547070441079
Llama 3.1 70B Base,underspecified context,Musique,Base,0.9941348973607038,0.5151975683890577,0.6786786786786787
Llama 3.1 70B Base,underspecified context,QASPER,Base,0.20909090909090908,0.8734177215189873,0.3374083129584352
Llama 3.1 70B Base,underspecified context,SQuAD 2.0,Base,0.9938900203665988,0.5511010728402033,0.70904467853251
Llama 3.1 70B Base,underspecified context,UMWP,Base,0.9212062256809338,0.5414522584333905,0.6820309686712279
Llama 3.1 70B Base,underspecified context,WorldSense,Base,0.7686496694995278,0.9421296296296297,0.8465938637545501
Llama 3.1 70B Base,underspecified intent,CoCoNot/Incomprehensible,Base,1.0,0.3877551020408163,0.5588235294117647
Llama 3.1 70B Base,underspecified intent,KUQ/Ambiguous,Base,0.7978142076502732,0.48344370860927155,0.6020618556701031
Llama 3.1 70B Base,underspecified intent,SituatedQA/Geo,Base,0.5957446808510638,0.43410852713178294,0.5022421524663677
Llama 3.1 70B Instruct,answer unknown,BB/Known unknowns,Instruct,0.9583333333333334,1.0,0.9787234042553191
Llama 3.1 70B Instruct,answer unknown,CoCoNot/Unknowns,Instruct,1.0,0.9850746268656716,0.9924812030075187
Llama 3.1 70B Instruct,answer unknown,CoCoNot/Unsupported,Instruct,0.9805825242718447,0.8416666666666667,0.905829596412556
Llama 3.1 70B Instruct,answer unknown,KUQ/Future unknowns,Instruct,0.8864628820960698,0.6226993865030674,0.7315315315315315
Llama 3.1 70B Instruct,answer unknown,KUQ/Unsolved problems,Instruct,0.8625,0.5872340425531914,0.6987341772151898
Llama 3.1 70B Instruct,false premise,CoCoNot/False presumptions,Instruct,0.9354838709677419,0.6987951807228916,0.8
Llama 3.1 70B Instruct,false premise,FalseQA,Instruct,0.8867469879518072,0.5356622998544396,0.6678765880217786
Llama 3.1 70B Instruct,false premise,KUQ/False assumptions,Instruct,0.864406779661017,0.575187969924812,0.690744920993228
Llama 3.1 70B Instruct,false premise,QAQA,Instruct,0.8571428571428571,0.4,0.5454545454545454
Llama 3.1 70B Instruct,stale,CoCoNot/Temporal,Instruct,1.0,0.6756756756756757,0.8064516129032258
Llama 3.1 70B Instruct,stale,FreshQA,Instruct,0.3010752688172043,0.5957446808510638,0.4
Llama 3.1 70B Instruct,subjective,CoCoNot/Humanizing,Instruct,1.0,0.9146341463414634,0.9554140127388535
Llama 3.1 70B Instruct,subjective,CoCoNot/Subjective,Instruct,1.0,0.6933333333333334,0.8188976377952756
Llama 3.1 70B Instruct,subjective,KUQ/Controversial,Instruct,0.9036697247706422,0.5845697329376854,0.7099099099099099
Llama 3.1 70B Instruct,subjective,MoralChoice,Instruct,0.9821428571428571,0.2426470588235294,0.3891509433962264
Llama 3.1 70B Instruct,underspecified context,ALCUNA,Instruct,0.9129782445611403,0.7026558891454965,0.7941272430668842
Llama 3.1 70B Instruct,underspecified context,BB/Disambiguate,Instruct,0.45,0.96,0.6127659574468085
Llama 3.1 70B Instruct,underspecified context,BBQ,Instruct,0.9658064516129032,0.8419572553430821,0.8996394230769231
Llama 3.1 70B Instruct,underspecified context,GPQA-Diamond,Instruct,0.9473684210526315,0.45,0.6101694915254238
Llama 3.1 70B Instruct,underspecified context,GSM8K,Instruct,0.9991266375545852,0.9431162407254741,0.9703138252756573
Llama 3.1 70B Instruct,underspecified context,MMLU History,Instruct,0.9333333333333333,0.358974358974359,0.5185185185185185
Llama 3.1 70B Instruct,underspecified context,MMLU Math,Instruct,0.98989898989899,0.7368421052631579,0.8448275862068966
Llama 3.1 70B Instruct,underspecified context,MediQ,Instruct,0.9921875,0.18026969481902058,0.3051051051051051
Llama 3.1 70B Instruct,underspecified context,Musique,Instruct,0.9011194029850746,0.7340425531914894,0.8090452261306532
Llama 3.1 70B Instruct,underspecified context,QASPER,Instruct,0.23588039867109634,0.8987341772151899,0.3736842105263158
Llama 3.1 70B Instruct,underspecified context,SQuAD 2.0,Instruct,0.9756944444444444,0.6346696781479391,0.7690728703386931
Llama 3.1 70B Instruct,underspecified context,UMWP,Instruct,0.9959709911361805,0.7062857142857143,0.8264794383149449
Llama 3.1 70B Instruct,underspecified context,WorldSense,Instruct,0.6670480549199085,0.6747685185185185,0.6708860759493671
Llama 3.1 70B Instruct,underspecified intent,CoCoNot/Incomprehensible,Instruct,1.0,0.8367346938775511,0.9111111111111111
Llama 3.1 70B Instruct,underspecified intent,KUQ/Ambiguous,Instruct,0.6749116607773852,0.6324503311258278,0.652991452991453
Llama 3.1 70B Instruct,underspecified intent,SituatedQA/Geo,Instruct,0.5573770491803278,0.5271317829457365,0.5418326693227091
Llama 3.1 70B Tulu 3 DPO,answer unknown,BB/Known unknowns,DPO,0.92,1.0,0.9583333333333334
Llama 3.1 70B Tulu 3 DPO,answer unknown,CoCoNot/Unknowns,DPO,1.0,1.0,1.0
Llama 3.1 70B Tulu 3 DPO,answer unknown,CoCoNot/Unsupported,DPO,0.9913793103448276,0.9583333333333334,0.9745762711864406
Llama 3.1 70B Tulu 3 DPO,answer unknown,KUQ/Future unknowns,DPO,0.8926174496644296,0.8159509202453987,0.8525641025641025
Llama 3.1 70B Tulu 3 DPO,answer unknown,KUQ/Unsolved problems,DPO,0.868421052631579,0.7021276595744681,0.7764705882352941
Llama 3.1 70B Tulu 3 DPO,false premise,CoCoNot/False presumptions,DPO,0.9565217391304348,0.7951807228915663,0.868421052631579
Llama 3.1 70B Tulu 3 DPO,false premise,FalseQA,DPO,0.874384236453202,0.5167394468704513,0.6495882891125343
Llama 3.1 70B Tulu 3 DPO,false premise,KUQ/False assumptions,DPO,0.9020618556701031,0.6578947368421053,0.7608695652173914
Llama 3.1 70B Tulu 3 DPO,false premise,QAQA,DPO,0.8186813186813187,0.5228070175438596,0.6381156316916489
Llama 3.1 70B Tulu 3 DPO,stale,CoCoNot/Temporal,DPO,1.0,0.8108108108108109,0.8955223880597015
Llama 3.1 70B Tulu 3 DPO,stale,FreshQA,DPO,0.3389830508474576,0.851063829787234,0.48484848484848486
Llama 3.1 70B Tulu 3 DPO,subjective,CoCoNot/Humanizing,DPO,1.0,0.9390243902439024,0.9685534591194969
Llama 3.1 70B Tulu 3 DPO,subjective,CoCoNot/Subjective,DPO,1.0,0.9466666666666667,0.9726027397260274
Llama 3.1 70B Tulu 3 DPO,subjective,KUQ/Controversial,DPO,0.9060150375939849,0.7151335311572701,0.7993366500829188
Llama 3.1 70B Tulu 3 DPO,subjective,MoralChoice,DPO,0.9851485148514851,0.2926470588235294,0.4512471655328798
Llama 3.1 70B Tulu 3 DPO,underspecified context,ALCUNA,DPO,0.8736083824492469,0.7702078521939953,0.8186560294568886
Llama 3.1 70B Tulu 3 DPO,underspecified context,BB/Disambiguate,DPO,0.6341463414634146,0.3466666666666667,0.4482758620689655
Llama 3.1 70B Tulu 3 DPO,underspecified context,BBQ,DPO,0.9403973509933775,0.8785151856017998,0.9084036056993312
Llama 3.1 70B Tulu 3 DPO,underspecified context,GPQA-Diamond,DPO,0.9629629629629629,0.65,0.7761194029850746
Llama 3.1 70B Tulu 3 DPO,underspecified context,GSM8K,DPO,1.0,0.8911788953009069,0.942458587619878
Llama 3.1 70B Tulu 3 DPO,underspecified context,MMLU History,DPO,1.0,0.41025641025641024,0.5818181818181818
Llama 3.1 70B Tulu 3 DPO,underspecified context,MMLU Math,DPO,0.9764705882352941,0.6240601503759399,0.7614678899082569
Llama 3.1 70B Tulu 3 DPO,underspecified context,MediQ,DPO,0.9779411764705882,0.09439318665720368,0.17216828478964402
Llama 3.1 70B Tulu 3 DPO,underspecified context,Musique,DPO,0.8923654568210263,0.5417933130699089,0.6742316784869976
Llama 3.1 70B Tulu 3 DPO,underspecified context,QASPER,DPO,0.2664359861591695,0.9746835443037974,0.41847826086956524
Llama 3.1 70B Tulu 3 DPO,underspecified context,SQuAD 2.0,DPO,0.9642857142857143,0.5945793337097685,0.7355920363255326
Llama 3.1 70B Tulu 3 DPO,underspecified context,UMWP,DPO,0.996523754345307,0.49142857142857144,0.6582472254114046
Llama 3.1 70B Tulu 3 DPO,underspecified context,WorldSense,DPO,0.5116618075801749,0.8125,0.627906976744186
Llama 3.1 70B Tulu 3 DPO,underspecified intent,CoCoNot/Incomprehensible,DPO,1.0,0.9387755102040817,0.968421052631579
Llama 3.1 70B Tulu 3 DPO,underspecified intent,KUQ/Ambiguous,DPO,0.7070707070707071,0.695364238410596,0.7011686143572621
Llama 3.1 70B Tulu 3 DPO,underspecified intent,SituatedQA/Geo,DPO,0.5022026431718062,0.8837209302325582,0.6404494382022472
Llama 3.1 70B Tulu 3 PPO RLVF,answer unknown,BB/Known unknowns,PPO RLVF,0.9583333333333334,1.0,0.9787234042553191
Llama 3.1 70B Tulu 3 PPO RLVF,answer unknown,CoCoNot/Unknowns,PPO RLVF,1.0,1.0,1.0
Llama 3.1 70B Tulu 3 PPO RLVF,answer unknown,CoCoNot/Unsupported,PPO RLVF,0.9663865546218487,0.9583333333333334,0.9623430962343096
Llama 3.1 70B Tulu 3 PPO RLVF,answer unknown,KUQ/Future unknowns,PPO RLVF,0.9125874125874126,0.8006134969325154,0.8529411764705882
Llama 3.1 70B Tulu 3 PPO RLVF,answer unknown,KUQ/Unsolved problems,PPO RLVF,0.8808290155440415,0.723404255319149,0.794392523364486
Llama 3.1 70B Tulu 3 PPO RLVF,false premise,CoCoNot/False presumptions,PPO RLVF,0.9710144927536232,0.8072289156626506,0.881578947368421
Llama 3.1 70B Tulu 3 PPO RLVF,false premise,FalseQA,PPO RLVF,0.8822055137844611,0.512372634643377,0.6482504604051565
Llama 3.1 70B Tulu 3 PPO RLVF,false premise,KUQ/False assumptions,PPO RLVF,0.9025641025641026,0.6616541353383458,0.7635574837310195
Llama 3.1 70B Tulu 3 PPO RLVF,false premise,QAQA,PPO RLVF,0.8272251308900523,0.5543859649122806,0.6638655462184874
Llama 3.1 70B Tulu 3 PPO RLVF,stale,CoCoNot/Temporal,PPO RLVF,1.0,0.918918918918919,0.9577464788732394
Llama 3.1 70B Tulu 3 PPO RLVF,stale,FreshQA,PPO RLVF,0.3333333333333333,0.8936170212765957,0.48554913294797686
Llama 3.1 70B Tulu 3 PPO RLVF,subjective,CoCoNot/Humanizing,PPO RLVF,1.0,0.9146341463414634,0.9554140127388535
Llama 3.1 70B Tulu 3 PPO RLVF,subjective,CoCoNot/Subjective,PPO RLVF,1.0,0.92,0.9583333333333334
Llama 3.1 70B Tulu 3 PPO RLVF,subjective,KUQ/Controversial,PPO RLVF,0.8996282527881041,0.7181008902077152,0.7986798679867987
Llama 3.1 70B Tulu 3 PPO RLVF,subjective,MoralChoice,PPO RLVF,0.9853658536585366,0.29705882352941176,0.45649717514124294
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,ALCUNA,PPO RLVF,0.8718116415958143,0.7696304849884527,0.817540631708065
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,BB/Disambiguate,PPO RLVF,0.7272727272727273,0.21333333333333335,0.32989690721649484
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,BBQ,PPO RLVF,0.9377245508982036,0.8807649043869517,0.9083526682134571
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,GPQA-Diamond,PPO RLVF,0.9629629629629629,0.65,0.7761194029850746
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,GSM8K,PPO RLVF,1.0,0.8779884583676835,0.9350307287093942
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,MMLU History,PPO RLVF,1.0,0.358974358974359,0.5283018867924528
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,MediQ,PPO RLVF,0.9907407407407407,0.07594038325053229,0.14106789716545814
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,Musique,PPO RLVF,0.8896848137535817,0.47188449848024316,0.6166832174776564
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,QASPER,PPO RLVF,0.2542955326460481,0.9367088607594937,0.4
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,SQuAD 2.0,PPO RLVF,0.9695528068506185,0.5753811405985318,0.7221828490432317
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,UMWP,PPO RLVF,0.9977116704805492,0.4982857142857143,0.6646341463414634
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified context,WorldSense,PPO RLVF,0.5175125089349535,0.8379629629629629,0.6398585947856827
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified intent,CoCoNot/Incomprehensible,PPO RLVF,1.0,0.8979591836734694,0.946236559139785
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified intent,KUQ/Ambiguous,PPO RLVF,0.708904109589041,0.6854304635761589,0.696969696969697
Llama 3.1 70B Tulu 3 PPO RLVF,underspecified intent,SituatedQA/Geo,PPO RLVF,0.49777777777777776,0.8682170542635659,0.632768361581921
Llama 3.1 70B Tulu 3 SFT,answer unknown,BB/Known unknowns,SFT,0.8518518518518519,1.0,0.92
Llama 3.1 70B Tulu 3 SFT,answer unknown,CoCoNot/Unknowns,SFT,1.0,1.0,1.0
Llama 3.1 70B Tulu 3 SFT,answer unknown,CoCoNot/Unsupported,SFT,0.9672131147540983,0.9833333333333333,0.9752066115702479
Llama 3.1 70B Tulu 3 SFT,answer unknown,KUQ/Future unknowns,SFT,0.915057915057915,0.7269938650306749,0.8102564102564103
Llama 3.1 70B Tulu 3 SFT,answer unknown,KUQ/Unsolved problems,SFT,0.8959537572254336,0.6595744680851063,0.7598039215686274
Llama 3.1 70B Tulu 3 SFT,false premise,CoCoNot/False presumptions,SFT,1.0,0.7590361445783133,0.863013698630137
Llama 3.1 70B Tulu 3 SFT,false premise,FalseQA,SFT,0.8558758314855875,0.5618631732168851,0.6783831282952548
Llama 3.1 70B Tulu 3 SFT,false premise,KUQ/False assumptions,SFT,0.8881578947368421,0.5075187969924813,0.645933014354067
Llama 3.1 70B Tulu 3 SFT,false premise,QAQA,SFT,0.7592592592592593,0.5754385964912281,0.654690618762475
Llama 3.1 70B Tulu 3 SFT,stale,CoCoNot/Temporal,SFT,1.0,0.918918918918919,0.9577464788732394
Llama 3.1 70B Tulu 3 SFT,stale,FreshQA,SFT,0.30864197530864196,0.5319148936170213,0.390625
Llama 3.1 70B Tulu 3 SFT,subjective,CoCoNot/Humanizing,SFT,1.0,0.975609756097561,0.9876543209876543
Llama 3.1 70B Tulu 3 SFT,subjective,CoCoNot/Subjective,SFT,1.0,0.9333333333333333,0.9655172413793104
Llama 3.1 70B Tulu 3 SFT,subjective,KUQ/Controversial,SFT,0.9111111111111111,0.6083086053412463,0.7295373665480427
Llama 3.1 70B Tulu 3 SFT,subjective,MoralChoice,SFT,0.9846153846153847,0.2823529411764706,0.43885714285714283
Llama 3.1 70B Tulu 3 SFT,underspecified context,ALCUNA,SFT,0.8923076923076924,0.7367205542725174,0.8070841239721696
Llama 3.1 70B Tulu 3 SFT,underspecified context,BB/Disambiguate,SFT,0.75,0.12,0.20689655172413793
Llama 3.1 70B Tulu 3 SFT,underspecified context,BBQ,SFT,0.8994544037412315,0.6490438695163104,0.7540019601437439
Llama 3.1 70B Tulu 3 SFT,underspecified context,GPQA-Diamond,SFT,0.96875,0.775,0.8611111111111112
Llama 3.1 70B Tulu 3 SFT,underspecified context,GSM8K,SFT,1.0,0.79719703215169,0.8871559633027523
Llama 3.1 70B Tulu 3 SFT,underspecified context,MMLU History,SFT,1.0,0.28205128205128205,0.44
Llama 3.1 70B Tulu 3 SFT,underspecified context,MediQ,SFT,0.9411764705882353,0.0227111426543648,0.04435204435204435
Llama 3.1 70B Tulu 3 SFT,underspecified context,Musique,SFT,0.9529914529914529,0.16945288753799392,0.28774193548387095
Llama 3.1 70B Tulu 3 SFT,underspecified context,QASPER,SFT,0.22945205479452055,0.8481012658227848,0.3611859838274933
Llama 3.1 70B Tulu 3 SFT,underspecified context,SQuAD 2.0,SFT,0.9790794979079498,0.264257481648786,0.4161849710982659
Llama 3.1 70B Tulu 3 SFT,underspecified context,UMWP,SFT,0.9987593052109182,0.46,0.6298904538341158
Llama 3.1 70B Tulu 3 SFT,underspecified context,WorldSense,SFT,0.4474948524365134,0.7546296296296297,0.5618267987936234
Llama 3.1 70B Tulu 3 SFT,underspecified intent,CoCoNot/Incomprehensible,SFT,1.0,0.9795918367346939,0.9896907216494846
Llama 3.1 70B Tulu 3 SFT,underspecified intent,KUQ/Ambiguous,SFT,0.7251908396946565,0.6291390728476821,0.6737588652482269
Llama 3.1 70B Tulu 3 SFT,underspecified intent,SituatedQA/Geo,SFT,0.4290909090909091,0.9147286821705426,0.5841584158415841
Llama 3.1 8B Base,answer unknown,BB/Known unknowns,Base,1.0,0.4782608695652174,0.6470588235294118
Llama 3.1 8B Base,answer unknown,CoCoNot/Unknowns,Base,1.0,0.5223880597014925,0.6862745098039216
Llama 3.1 8B Base,answer unknown,CoCoNot/Unsupported,Base,0.7971014492753623,0.4583333333333333,0.582010582010582
Llama 3.1 8B Base,answer unknown,KUQ/Future unknowns,Base,0.9333333333333333,0.4723926380368098,0.6272912423625254
Llama 3.1 8B Base,answer unknown,KUQ/Unsolved problems,Base,0.8394160583941606,0.48936170212765956,0.6182795698924731
Llama 3.1 8B Base,false premise,CoCoNot/False presumptions,Base,0.8421052631578947,0.3855421686746988,0.5289256198347108
Llama 3.1 8B Base,false premise,FalseQA,Base,0.7149532710280374,0.22270742358078602,0.33962264150943394
Llama 3.1 8B Base,false premise,KUQ/False assumptions,Base,0.9097744360902256,0.4548872180451128,0.606516290726817
Llama 3.1 8B Base,false premise,QAQA,Base,0.81,0.28421052631578947,0.42077922077922075
Llama 3.1 8B Base,stale,CoCoNot/Temporal,Base,1.0,0.4864864864864865,0.6545454545454545
Llama 3.1 8B Base,stale,FreshQA,Base,0.5102040816326531,0.5319148936170213,0.5208333333333334
Llama 3.1 8B Base,subjective,CoCoNot/Humanizing,Base,1.0,0.34146341463414637,0.509090909090909
Llama 3.1 8B Base,subjective,CoCoNot/Subjective,Base,1.0,0.52,0.6842105263157895
Llama 3.1 8B Base,subjective,KUQ/Controversial,Base,0.8641304347826086,0.47181008902077154,0.6103646833013435
Llama 3.1 8B Base,subjective,MoralChoice,Base,0.5661605206073753,0.38382352941176473,0.4574934268185802
Llama 3.1 8B Base,underspecified context,ALCUNA,Base,0.6748732802317161,0.5393518518518519,0.5995496944355098
Llama 3.1 8B Base,underspecified context,BB/Disambiguate,Base,0.5357142857142857,0.4,0.4580152671755725
Llama 3.1 8B Base,underspecified context,BBQ,Base,0.9195402298850575,0.4499437570303712,0.6042296072507553
Llama 3.1 8B Base,underspecified context,GPQA-Diamond,Base,0.875,0.175,0.2916666666666667
Llama 3.1 8B Base,underspecified context,GSM8K,Base,0.8106235565819861,0.2893652102225886,0.4264884568651276
Llama 3.1 8B Base,underspecified context,MMLU Math,Base,0.8235294117647058,0.10526315789473684,0.18666666666666668
Llama 3.1 8B Base,underspecified context,MediQ,Base,0.9891891891891892,0.12987934705464868,0.22961104140526975
Llama 3.1 8B Base,underspecified context,Musique,Base,0.993103448275862,0.547112462006079,0.7055365017148456
Llama 3.1 8B Base,underspecified context,QASPER,Base,0.1349206349206349,0.8607594936708861,0.2332761578044597
Llama 3.1 8B Base,underspecified context,SQuAD 2.0,Base,0.9777777777777777,0.5217391304347826,0.6804123711340206
Llama 3.1 8B Base,underspecified context,UMWP,Base,0.8876629889669007,0.5060034305317325,0.6445739257101238
Llama 3.1 8B Base,underspecified context,WorldSense,Base,0.6776429809358753,0.9050925925925926,0.7750247770069376
Llama 3.1 8B Base,underspecified intent,CoCoNot/Incomprehensible,Base,1.0,0.40816326530612246,0.5797101449275363
Llama 3.1 8B Base,underspecified intent,KUQ/Ambiguous,Base,0.765625,0.4867549668874172,0.5951417004048583
Llama 3.1 8B Base,underspecified intent,SituatedQA/Geo,Base,0.5578947368421052,0.4108527131782946,0.4732142857142857
Llama 3.1 8B Instruct,answer unknown,BB/Known unknowns,Instruct,0.92,1.0,0.9583333333333334
Llama 3.1 8B Instruct,answer unknown,CoCoNot/Unknowns,Instruct,1.0,0.9552238805970149,0.9770992366412213
Llama 3.1 8B Instruct,answer unknown,CoCoNot/Unsupported,Instruct,0.9811320754716981,0.8666666666666667,0.9203539823008849
Llama 3.1 8B Instruct,answer unknown,KUQ/Future unknowns,Instruct,0.8507462686567164,0.6993865030674846,0.7676767676767676
Llama 3.1 8B Instruct,answer unknown,KUQ/Unsolved problems,Instruct,0.7875647668393783,0.6468085106382979,0.7102803738317757
Llama 3.1 8B Instruct,false premise,CoCoNot/False presumptions,Instruct,0.8636363636363636,0.6867469879518072,0.7651006711409396
Llama 3.1 8B Instruct,false premise,FalseQA,Instruct,0.8346055979643766,0.4774381368267831,0.6074074074074074
Llama 3.1 8B Instruct,false premise,KUQ/False assumptions,Instruct,0.7782805429864253,0.6466165413533834,0.7063655030800822
Llama 3.1 8B Instruct,false premise,QAQA,Instruct,0.7515923566878981,0.41403508771929826,0.5339366515837104
Llama 3.1 8B Instruct,stale,CoCoNot/Temporal,Instruct,1.0,0.7567567567567568,0.8615384615384616
Llama 3.1 8B Instruct,stale,FreshQA,Instruct,0.2595419847328244,0.723404255319149,0.38202247191011235
Llama 3.1 8B Instruct,subjective,CoCoNot/Humanizing,Instruct,1.0,0.926829268292683,0.9620253164556962
Llama 3.1 8B Instruct,subjective,CoCoNot/Subjective,Instruct,1.0,0.76,0.8636363636363636
Llama 3.1 8B Instruct,subjective,KUQ/Controversial,Instruct,0.8419117647058824,0.6795252225519288,0.7520525451559934
Llama 3.1 8B Instruct,subjective,MoralChoice,Instruct,0.9772727272727273,0.2529411764705882,0.40186915887850466
Llama 3.1 8B Instruct,underspecified context,ALCUNA,Instruct,0.8405707196029777,0.7823325635103926,0.8104066985645934
Llama 3.1 8B Instruct,underspecified context,BB/Disambiguate,Instruct,0.3333333333333333,0.7866666666666666,0.46825396825396826
Llama 3.1 8B Instruct,underspecified context,BBQ,Instruct,0.806760847628658,0.8993250843644545,0.850531914893617
Llama 3.1 8B Instruct,underspecified context,GPQA-Diamond,Instruct,1.0,0.525,0.6885245901639344
Llama 3.1 8B Instruct,underspecified context,GSM8K,Instruct,0.997338065661047,0.9266281945589447,0.9606837606837607
Llama 3.1 8B Instruct,underspecified context,MMLU History,Instruct,0.8823529411764706,0.38461538461538464,0.5357142857142857
Llama 3.1 8B Instruct,underspecified context,MMLU Math,Instruct,0.9666666666666667,0.6541353383458647,0.7802690582959642
Llama 3.1 8B Instruct,underspecified context,MediQ,Instruct,0.9740932642487047,0.1334279630943932,0.23470661672908863
Llama 3.1 8B Instruct,underspecified context,Musique,Instruct,0.8397790055248618,0.8085106382978723,0.8238482384823849
Llama 3.1 8B Instruct,underspecified context,QASPER,Instruct,0.259927797833935,0.9113924050632911,0.4044943820224719
Llama 3.1 8B Instruct,underspecified context,SQuAD 2.0,Instruct,0.9661654135338346,0.5804630152456239,0.7252204585537919
Llama 3.1 8B Instruct,underspecified context,UMWP,Instruct,0.9935543278084714,0.6165714285714285,0.7609308885754584
Llama 3.1 8B Instruct,underspecified context,WorldSense,Instruct,0.403387220939184,0.6064814814814815,0.4845122515025428
Llama 3.1 8B Instruct,underspecified intent,CoCoNot/Incomprehensible,Instruct,1.0,0.9183673469387755,0.9574468085106383
Llama 3.1 8B Instruct,underspecified intent,KUQ/Ambiguous,Instruct,0.5755813953488372,0.6556291390728477,0.6130030959752322
Llama 3.1 8B Instruct,underspecified intent,SituatedQA/Geo,Instruct,0.5866666666666667,0.6821705426356589,0.6308243727598566
Llama 3.1 8B Tulu 3 DPO,answer unknown,BB/Known unknowns,DPO,0.8148148148148148,0.9565217391304348,0.88
Llama 3.1 8B Tulu 3 DPO,answer unknown,CoCoNot/Unknowns,DPO,1.0,0.9850746268656716,0.9924812030075187
Llama 3.1 8B Tulu 3 DPO,answer unknown,CoCoNot/Unsupported,DPO,0.9910714285714286,0.925,0.9568965517241379
Llama 3.1 8B Tulu 3 DPO,answer unknown,KUQ/Future unknowns,DPO,0.9195402298850575,0.7361963190184049,0.817717206132879
Llama 3.1 8B Tulu 3 DPO,answer unknown,KUQ/Unsolved problems,DPO,0.9075144508670521,0.6680851063829787,0.7696078431372549
Llama 3.1 8B Tulu 3 DPO,false premise,CoCoNot/False presumptions,DPO,0.9130434782608695,0.7590361445783133,0.8289473684210527
Llama 3.1 8B Tulu 3 DPO,false premise,FalseQA,DPO,0.8580060422960725,0.413391557496361,0.5579567779960707
Llama 3.1 8B Tulu 3 DPO,false premise,KUQ/False assumptions,DPO,0.9192546583850931,0.556390977443609,0.6932084309133489
Llama 3.1 8B Tulu 3 DPO,false premise,QAQA,DPO,0.7696629213483146,0.4807017543859649,0.591792656587473
Llama 3.1 8B Tulu 3 DPO,stale,CoCoNot/Temporal,DPO,1.0,0.7837837837837838,0.8787878787878788
Llama 3.1 8B Tulu 3 DPO,stale,FreshQA,DPO,0.3418803418803419,0.851063829787234,0.4878048780487805
Llama 3.1 8B Tulu 3 DPO,subjective,CoCoNot/Humanizing,DPO,1.0,0.9390243902439024,0.9685534591194969
Llama 3.1 8B Tulu 3 DPO,subjective,CoCoNot/Subjective,DPO,1.0,0.8666666666666667,0.9285714285714286
Llama 3.1 8B Tulu 3 DPO,subjective,KUQ/Controversial,DPO,0.9240506329113924,0.6498516320474778,0.7630662020905923
Llama 3.1 8B Tulu 3 DPO,subjective,MoralChoice,DPO,0.9792746113989638,0.27794117647058825,0.4329896907216495
Llama 3.1 8B Tulu 3 DPO,underspecified context,ALCUNA,DPO,0.8345588235294118,0.5242494226327945,0.6439716312056738
Llama 3.1 8B Tulu 3 DPO,underspecified context,BB/Disambiguate,DPO,0.46153846153846156,0.16,0.2376237623762376
Llama 3.1 8B Tulu 3 DPO,underspecified context,BBQ,DPO,0.9141295862607338,0.6586051743532059,0.7656096763648251
Llama 3.1 8B Tulu 3 DPO,underspecified context,GPQA-Diamond,DPO,1.0,0.175,0.2978723404255319
Llama 3.1 8B Tulu 3 DPO,underspecified context,GSM8K,DPO,0.9978165938864629,0.7535037098103875,0.8586190699859089
Llama 3.1 8B Tulu 3 DPO,underspecified context,MMLU History,DPO,1.0,0.15384615384615385,0.26666666666666666
Llama 3.1 8B Tulu 3 DPO,underspecified context,MMLU Math,DPO,0.9318181818181818,0.3082706766917293,0.4632768361581921
Llama 3.1 8B Tulu 3 DPO,underspecified context,MediQ,DPO,0.9302325581395349,0.028388928317955996,0.05509641873278237
Llama 3.1 8B Tulu 3 DPO,underspecified context,Musique,DPO,0.953125,0.18541033434650456,0.3104325699745547
Llama 3.1 8B Tulu 3 DPO,underspecified context,QASPER,DPO,0.29069767441860467,0.9493670886075949,0.44510385756676557
Llama 3.1 8B Tulu 3 DPO,underspecified context,SQuAD 2.0,DPO,0.9781818181818182,0.3037831733483907,0.4635932787591555
Llama 3.1 8B Tulu 3 DPO,underspecified context,UMWP,DPO,1.0,0.3177142857142857,0.4822202948829141
Llama 3.1 8B Tulu 3 DPO,underspecified context,WorldSense,DPO,0.3913301662707839,0.7627314814814815,0.5172684458398744
Llama 3.1 8B Tulu 3 DPO,underspecified intent,CoCoNot/Incomprehensible,DPO,1.0,0.8775510204081632,0.9347826086956522
Llama 3.1 8B Tulu 3 DPO,underspecified intent,KUQ/Ambiguous,DPO,0.7673469387755102,0.6225165562913907,0.6873857404021938
Llama 3.1 8B Tulu 3 DPO,underspecified intent,SituatedQA/Geo,DPO,0.49038461538461536,0.7906976744186046,0.6053412462908012
Llama 3.1 8B Tulu 3 PPO RLVF,answer unknown,BB/Known unknowns,PPO RLVF,0.9565217391304348,0.9565217391304348,0.9565217391304348
Llama 3.1 8B Tulu 3 PPO RLVF,answer unknown,CoCoNot/Unknowns,PPO RLVF,1.0,0.9850746268656716,0.9924812030075187
Llama 3.1 8B Tulu 3 PPO RLVF,answer unknown,CoCoNot/Unsupported,PPO RLVF,0.9821428571428571,0.9166666666666666,0.9482758620689655
Llama 3.1 8B Tulu 3 PPO RLVF,answer unknown,KUQ/Future unknowns,PPO RLVF,0.9446640316205533,0.7331288343558282,0.8255613126079447
Llama 3.1 8B Tulu 3 PPO RLVF,answer unknown,KUQ/Unsolved problems,PPO RLVF,0.9161676646706587,0.6510638297872341,0.7611940298507462
Llama 3.1 8B Tulu 3 PPO RLVF,false premise,CoCoNot/False presumptions,PPO RLVF,0.9375,0.7228915662650602,0.8163265306122449
Llama 3.1 8B Tulu 3 PPO RLVF,false premise,FalseQA,PPO RLVF,0.8753993610223643,0.3988355167394469,0.548
Llama 3.1 8B Tulu 3 PPO RLVF,false premise,KUQ/False assumptions,PPO RLVF,0.9151515151515152,0.5676691729323309,0.7006960556844548
Llama 3.1 8B Tulu 3 PPO RLVF,false premise,QAQA,PPO RLVF,0.7707006369426752,0.4245614035087719,0.5475113122171946
Llama 3.1 8B Tulu 3 PPO RLVF,stale,CoCoNot/Temporal,PPO RLVF,1.0,0.8648648648648649,0.927536231884058
Llama 3.1 8B Tulu 3 PPO RLVF,stale,FreshQA,PPO RLVF,0.36607142857142855,0.8723404255319149,0.5157232704402516
Llama 3.1 8B Tulu 3 PPO RLVF,subjective,CoCoNot/Humanizing,PPO RLVF,1.0,0.9024390243902439,0.9487179487179487
Llama 3.1 8B Tulu 3 PPO RLVF,subjective,CoCoNot/Subjective,PPO RLVF,1.0,0.8,0.8888888888888888
Llama 3.1 8B Tulu 3 PPO RLVF,subjective,KUQ/Controversial,PPO RLVF,0.9452054794520548,0.6142433234421365,0.7446043165467626
Llama 3.1 8B Tulu 3 PPO RLVF,subjective,MoralChoice,PPO RLVF,0.9781420765027322,0.26323529411764707,0.4148319814600232
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,ALCUNA,PPO RLVF,0.8702757916241062,0.49191685912240185,0.6285503504241977
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,BB/Disambiguate,PPO RLVF,0.5357142857142857,0.2,0.2912621359223301
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,BBQ,PPO RLVF,0.9324324324324325,0.6209223847019123,0.7454422687373397
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,GPQA-Diamond,PPO RLVF,1.0,0.225,0.3673469387755102
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,GSM8K,PPO RLVF,1.0,0.7452596867271228,0.8540387340576288
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,MMLU History,PPO RLVF,1.0,0.15384615384615385,0.26666666666666666
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,MMLU Math,PPO RLVF,0.967741935483871,0.22556390977443608,0.36585365853658536
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,MediQ,PPO RLVF,1.0,0.029098651525904896,0.05655172413793103
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,Musique,PPO RLVF,0.9873417721518988,0.11854103343465046,0.21166892808683854
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,QASPER,PPO RLVF,0.2878787878787879,0.9620253164556962,0.44314868804664725
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,SQuAD 2.0,PPO RLVF,0.9774266365688488,0.24449463579898362,0.3911472448057814
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,UMWP,PPO RLVF,1.0,0.316,0.48024316109422494
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified context,WorldSense,PPO RLVF,0.3969465648854962,0.7222222222222222,0.5123152709359606
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified intent,CoCoNot/Incomprehensible,PPO RLVF,1.0,0.9183673469387755,0.9574468085106383
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified intent,KUQ/Ambiguous,PPO RLVF,0.7922077922077922,0.6059602649006622,0.6866791744840526
Llama 3.1 8B Tulu 3 PPO RLVF,underspecified intent,SituatedQA/Geo,PPO RLVF,0.5294117647058824,0.7674418604651163,0.6265822784810127
Llama 3.1 8B Tulu 3 SFT,answer unknown,BB/Known unknowns,SFT,0.9545454545454546,0.9130434782608695,0.9333333333333333
Llama 3.1 8B Tulu 3 SFT,answer unknown,CoCoNot/Unknowns,SFT,1.0,0.9850746268656716,0.9924812030075187
Llama 3.1 8B Tulu 3 SFT,answer unknown,CoCoNot/Unsupported,SFT,0.9508196721311475,0.9666666666666667,0.9586776859504132
Llama 3.1 8B Tulu 3 SFT,answer unknown,KUQ/Future unknowns,SFT,0.9230769230769231,0.6257668711656442,0.7458866544789763
Llama 3.1 8B Tulu 3 SFT,answer unknown,KUQ/Unsolved problems,SFT,0.9124087591240876,0.5319148936170213,0.6720430107526881
Llama 3.1 8B Tulu 3 SFT,false premise,CoCoNot/False presumptions,SFT,0.9814814814814815,0.6385542168674698,0.7737226277372263
Llama 3.1 8B Tulu 3 SFT,false premise,FalseQA,SFT,0.84375,0.43231441048034935,0.5717035611164581
Llama 3.1 8B Tulu 3 SFT,false premise,KUQ/False assumptions,SFT,0.9323308270676691,0.46616541353383456,0.6215538847117794
Llama 3.1 8B Tulu 3 SFT,false premise,QAQA,SFT,0.7054794520547946,0.36140350877192984,0.4779582366589327
Llama 3.1 8B Tulu 3 SFT,stale,CoCoNot/Temporal,SFT,1.0,0.7297297297297297,0.84375
Llama 3.1 8B Tulu 3 SFT,stale,FreshQA,SFT,0.3472222222222222,0.5319148936170213,0.42016806722689076
Llama 3.1 8B Tulu 3 SFT,subjective,CoCoNot/Humanizing,SFT,1.0,0.975609756097561,0.9876543209876543
Llama 3.1 8B Tulu 3 SFT,subjective,CoCoNot/Subjective,SFT,1.0,0.7066666666666667,0.828125
Llama 3.1 8B Tulu 3 SFT,subjective,KUQ/Controversial,SFT,0.9615384615384616,0.5192878338278932,0.674373795761079
Llama 3.1 8B Tulu 3 SFT,subjective,MoralChoice,SFT,0.9776536312849162,0.25735294117647056,0.4074505238649593
Llama 3.1 8B Tulu 3 SFT,underspecified context,ALCUNA,SFT,0.8929016189290162,0.41397228637413397,0.565680473372781
Llama 3.1 8B Tulu 3 SFT,underspecified context,BB/Disambiguate,SFT,0.375,0.04,0.07228915662650602
Llama 3.1 8B Tulu 3 SFT,underspecified context,BBQ,SFT,0.8284823284823285,0.4482564679415073,0.5817518248175182
Llama 3.1 8B Tulu 3 SFT,underspecified context,GPQA-Diamond,SFT,0.7222222222222222,0.325,0.4482758620689655
Llama 3.1 8B Tulu 3 SFT,underspecified context,GSM8K,SFT,0.995221027479092,0.686727122835944,0.8126829268292682
Llama 3.1 8B Tulu 3 SFT,underspecified context,MMLU History,SFT,1.0,0.05128205128205128,0.0975609756097561
Llama 3.1 8B Tulu 3 SFT,underspecified context,MMLU Math,SFT,0.9736842105263158,0.2781954887218045,0.4327485380116959
Llama 3.1 8B Tulu 3 SFT,underspecified context,MediQ,SFT,0.9545454545454546,0.014904187366926898,0.029350104821802937
Llama 3.1 8B Tulu 3 SFT,underspecified context,Musique,SFT,0.9705882352941176,0.02507598784194529,0.04888888888888889
Llama 3.1 8B Tulu 3 SFT,underspecified context,QASPER,SFT,0.23137254901960785,0.7468354430379747,0.3532934131736527
Llama 3.1 8B Tulu 3 SFT,underspecified context,SQuAD 2.0,SFT,0.9727891156462585,0.16149068322981366,0.276997578692494
Llama 3.1 8B Tulu 3 SFT,underspecified context,UMWP,SFT,0.9824902723735408,0.2885714285714286,0.446113074204947
Llama 3.1 8B Tulu 3 SFT,underspecified context,WorldSense,SFT,0.3848334514528703,0.6284722222222222,0.47736263736263734
Llama 3.1 8B Tulu 3 SFT,underspecified intent,CoCoNot/Incomprehensible,SFT,1.0,0.9591836734693877,0.9791666666666666
Llama 3.1 8B Tulu 3 SFT,underspecified intent,KUQ/Ambiguous,SFT,0.7932692307692307,0.5463576158940397,0.6470588235294118
Llama 3.1 8B Tulu 3 SFT,underspecified intent,SituatedQA/Geo,SFT,0.46116504854368934,0.7364341085271318,0.5671641791044776
Llama 3.3 70B Instruct,answer unknown,BB/Known unknowns,NA,1.0,1.0,1.0
Llama 3.3 70B Instruct,answer unknown,CoCoNot/Unknowns,NA,1.0,0.9701492537313433,0.9848484848484849
Llama 3.3 70B Instruct,answer unknown,CoCoNot/Unsupported,NA,0.9626168224299065,0.8583333333333333,0.9074889867841409
Llama 3.3 70B Instruct,answer unknown,KUQ/Future unknowns,NA,0.9230769230769231,0.6993865030674846,0.7958115183246073
Llama 3.3 70B Instruct,answer unknown,KUQ/Unsolved problems,NA,0.8863636363636364,0.6638297872340425,0.7591240875912408
Llama 3.3 70B Instruct,false premise,CoCoNot/False presumptions,NA,0.953125,0.7349397590361446,0.8299319727891157
Llama 3.3 70B Instruct,false premise,FalseQA,NA,0.8834745762711864,0.6069868995633187,0.719585849870578
Llama 3.3 70B Instruct,false premise,KUQ/False assumptions,NA,0.9050279329608939,0.6090225563909775,0.7280898876404495
Llama 3.3 70B Instruct,false premise,QAQA,NA,0.8368794326241135,0.41403508771929826,0.5539906103286385
Llama 3.3 70B Instruct,stale,CoCoNot/Temporal,NA,1.0,0.6486486486486487,0.7868852459016393
Llama 3.3 70B Instruct,stale,FreshQA,NA,0.35714285714285715,0.6382978723404256,0.4580152671755725
Llama 3.3 70B Instruct,subjective,CoCoNot/Humanizing,NA,1.0,0.926829268292683,0.9620253164556962
Llama 3.3 70B Instruct,subjective,CoCoNot/Subjective,NA,1.0,0.5866666666666667,0.7394957983193278
Llama 3.3 70B Instruct,subjective,KUQ/Controversial,NA,0.9308943089430894,0.6795252225519288,0.7855917667238422
Llama 3.3 70B Instruct,subjective,MoralChoice,NA,0.9821428571428571,0.2426470588235294,0.3891509433962264
Llama 3.3 70B Instruct,underspecified context,ALCUNA,NA,0.9222054380664653,0.7049653579676675,0.7990837696335078
Llama 3.3 70B Instruct,underspecified context,BB/Disambiguate,NA,0.4397590361445783,0.9733333333333334,0.6058091286307054
Llama 3.3 70B Instruct,underspecified context,BBQ,NA,0.9799585348997927,0.7975253093363329,0.8793798449612403
Llama 3.3 70B Instruct,underspecified context,GPQA-Diamond,NA,0.9375,0.375,0.5357142857142857
Llama 3.3 70B Instruct,underspecified context,GSM8K,NA,1.0,0.910964550700742,0.9534081104400345
Llama 3.3 70B Instruct,underspecified context,MMLU History,NA,0.8888888888888888,0.20512820512820512,0.3333333333333333
Llama 3.3 70B Instruct,underspecified context,MMLU Math,NA,1.0,0.48120300751879697,0.649746192893401
Llama 3.3 70B Instruct,underspecified context,MediQ,NA,0.9819494584837545,0.1930447125621008,0.32265717674970346
Llama 3.3 70B Instruct,underspecified context,Musique,NA,0.8842195540308748,0.7834346504559271,0.830781627719581
Llama 3.3 70B Instruct,underspecified context,QASPER,NA,0.2602739726027397,0.9620253164556962,0.40970350404312667
Llama 3.3 70B Instruct,underspecified context,SQuAD 2.0,NA,0.9739542225730071,0.6967814793901751,0.8123765635286373
Llama 3.3 70B Instruct,underspecified context,UMWP,NA,0.9946751863684771,0.5337142857142857,0.6946820379323169
Llama 3.3 70B Instruct,underspecified context,WorldSense,NA,0.6520179372197309,0.8414351851851852,0.7347145022738757
Llama 3.3 70B Instruct,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.7142857142857143,0.8333333333333334
Llama 3.3 70B Instruct,underspecified intent,KUQ/Ambiguous,NA,0.7388059701492538,0.6556291390728477,0.6947368421052632
Llama 3.3 70B Instruct,underspecified intent,SituatedQA/Geo,NA,0.6902654867256637,0.6046511627906976,0.6446280991735537
Mistral 7B v0.3,answer unknown,BB/Known unknowns,NA,0.8518518518518519,1.0,0.92
Mistral 7B v0.3,answer unknown,CoCoNot/Unknowns,NA,1.0,0.9552238805970149,0.9770992366412213
Mistral 7B v0.3,answer unknown,CoCoNot/Unsupported,NA,1.0,0.8166666666666667,0.8990825688073395
Mistral 7B v0.3,answer unknown,KUQ/Future unknowns,NA,0.8643410852713178,0.6840490797546013,0.7636986301369864
Mistral 7B v0.3,answer unknown,KUQ/Unsolved problems,NA,0.8571428571428571,0.6127659574468085,0.7146401985111662
Mistral 7B v0.3,false premise,CoCoNot/False presumptions,NA,0.9365079365079365,0.7108433734939759,0.8082191780821918
Mistral 7B v0.3,false premise,FalseQA,NA,0.8762376237623762,0.5152838427947598,0.6489459211732356
Mistral 7B v0.3,false premise,KUQ/False assumptions,NA,0.8782051282051282,0.5150375939849624,0.6492890995260664
Mistral 7B v0.3,false premise,QAQA,NA,0.8141025641025641,0.4456140350877193,0.5759637188208617
Mistral 7B v0.3,stale,CoCoNot/Temporal,NA,1.0,0.6756756756756757,0.8064516129032258
Mistral 7B v0.3,stale,FreshQA,NA,0.29473684210526313,0.5957446808510638,0.39436619718309857
Mistral 7B v0.3,subjective,CoCoNot/Humanizing,NA,1.0,0.8536585365853658,0.9210526315789473
Mistral 7B v0.3,subjective,CoCoNot/Subjective,NA,1.0,0.6533333333333333,0.7903225806451613
Mistral 7B v0.3,subjective,KUQ/Controversial,NA,0.9158415841584159,0.5489614243323442,0.686456400742115
Mistral 7B v0.3,subjective,MoralChoice,NA,0.9679144385026738,0.2661764705882353,0.41753171856978083
Mistral 7B v0.3,underspecified context,ALCUNA,NA,0.9288537549407114,0.6784064665127021,0.7841174507841174
Mistral 7B v0.3,underspecified context,BB/Disambiguate,NA,0.47619047619047616,0.13333333333333333,0.20833333333333334
Mistral 7B v0.3,underspecified context,BBQ,NA,0.8626402993051844,0.9077615298087739,0.8846259249109345
Mistral 7B v0.3,underspecified context,GPQA-Diamond,NA,0.84,0.525,0.6461538461538462
Mistral 7B v0.3,underspecified context,GSM8K,NA,0.9652650822669104,0.8705688375927453,0.9154746423927178
Mistral 7B v0.3,underspecified context,MMLU Math,NA,0.8367346938775511,0.6165413533834586,0.70995670995671
Mistral 7B v0.3,underspecified context,MediQ,NA,0.955810147299509,0.41447835344215755,0.5782178217821782
Mistral 7B v0.3,underspecified context,Musique,NA,0.7018518518518518,0.8639817629179332,0.7745231607629428
Mistral 7B v0.3,underspecified context,QASPER,NA,0.25084745762711863,0.9367088607594937,0.39572192513368987
Mistral 7B v0.3,underspecified context,SQuAD 2.0,NA,0.9517543859649122,0.6126482213438735,0.7454482995534181
Mistral 7B v0.3,underspecified context,UMWP,NA,0.9307017543859649,0.6062857142857143,0.7342560553633218
Mistral 7B v0.3,underspecified context,WorldSense,NA,0.4090909090909091,0.8333333333333334,0.5487804878048781
Mistral 7B v0.3,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.8367346938775511,0.9111111111111111
Mistral 7B v0.3,underspecified intent,KUQ/Ambiguous,NA,0.7063197026022305,0.6291390728476821,0.6654991243432574
Mistral 7B v0.3,underspecified intent,SituatedQA/Geo,NA,0.5851851851851851,0.6124031007751938,0.5984848484848485
OLMo 7B,answer unknown,BB/Known unknowns,NA,0.8518518518518519,1.0,0.92
OLMo 7B,answer unknown,CoCoNot/Unknowns,NA,1.0,0.8507462686567164,0.9193548387096774
OLMo 7B,answer unknown,CoCoNot/Unsupported,NA,0.9878048780487805,0.675,0.801980198019802
OLMo 7B,answer unknown,KUQ/Future unknowns,NA,0.8708333333333333,0.6411042944785276,0.7385159010600707
OLMo 7B,answer unknown,KUQ/Unsolved problems,NA,0.8098159509202454,0.5617021276595745,0.6633165829145728
OLMo 7B,false premise,CoCoNot/False presumptions,NA,0.9322033898305084,0.6626506024096386,0.7746478873239436
OLMo 7B,false premise,FalseQA,NA,0.7945492662473794,0.5516739446870451,0.6512027491408935
OLMo 7B,false premise,KUQ/False assumptions,NA,0.8011695906432749,0.5150375939849624,0.6270022883295194
OLMo 7B,false premise,QAQA,NA,0.7473118279569892,0.48771929824561405,0.5902335456475584
OLMo 7B,stale,CoCoNot/Temporal,NA,1.0,0.6756756756756757,0.8064516129032258
OLMo 7B,stale,FreshQA,NA,0.32061068702290074,0.8936170212765957,0.47191011235955055
OLMo 7B,subjective,CoCoNot/Humanizing,NA,1.0,0.6341463414634146,0.7761194029850746
OLMo 7B,subjective,CoCoNot/Subjective,NA,1.0,0.7466666666666667,0.8549618320610687
OLMo 7B,subjective,KUQ/Controversial,NA,0.8365384615384616,0.516320474777448,0.6385321100917432
OLMo 7B,subjective,MoralChoice,NA,0.9748427672955975,0.22794117647058823,0.3694874851013111
OLMo 7B,underspecified context,ALCUNA,NA,0.6858902575587906,0.7072748267898383,0.6964184195565662
OLMo 7B,underspecified context,BB/Disambiguate,NA,0.5238095238095238,0.29333333333333333,0.37606837606837606
OLMo 7B,underspecified context,BBQ,NA,0.9129852744310576,0.7671541057367829,0.8337408312958435
OLMo 7B,underspecified context,GSM8K,NA,0.9698492462311558,0.47732893652102226,0.6397790055248619
OLMo 7B,underspecified context,MMLU History,NA,0.875,0.1794871794871795,0.2978723404255319
OLMo 7B,underspecified context,MMLU Math,NA,0.84,0.3157894736842105,0.45901639344262296
OLMo 7B,underspecified context,MediQ,NA,0.9285714285714286,0.10149041873669269,0.18298144593730006
OLMo 7B,underspecified context,Musique,NA,0.8197932053175776,0.4217325227963526,0.5569493226292022
OLMo 7B,underspecified context,QASPER,NA,0.30165289256198347,0.9240506329113924,0.45482866043613707
OLMo 7B,underspecified context,SQuAD 2.0,NA,0.962772785622593,0.4234895539243365,0.5882352941176471
OLMo 7B,underspecified context,UMWP,NA,0.9532293986636972,0.24457142857142858,0.38926784902228284
OLMo 7B,underspecified context,WorldSense,NA,0.43004418262150224,0.6759259259259259,0.5256525652565257
OLMo 7B,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.7551020408163265,0.8604651162790697
OLMo 7B,underspecified intent,KUQ/Ambiguous,NA,0.6923076923076923,0.5364238410596026,0.6044776119402985
OLMo 7B,underspecified intent,SituatedQA/Geo,NA,0.4602272727272727,0.627906976744186,0.5311475409836065
Qwen2.5 32B,answer unknown,BB/Known unknowns,NA,1.0,1.0,1.0
Qwen2.5 32B,answer unknown,CoCoNot/Unknowns,NA,1.0,0.9850746268656716,0.9924812030075187
Qwen2.5 32B,answer unknown,CoCoNot/Unsupported,NA,0.9910714285714286,0.925,0.9568965517241379
Qwen2.5 32B,answer unknown,KUQ/Future unknowns,NA,0.889344262295082,0.6656441717791411,0.7614035087719299
Qwen2.5 32B,answer unknown,KUQ/Unsolved problems,NA,0.8606060606060606,0.6042553191489362,0.71
Qwen2.5 32B,false premise,CoCoNot/False presumptions,NA,0.9393939393939394,0.7469879518072289,0.8322147651006712
Qwen2.5 32B,false premise,FalseQA,NA,0.8906882591093117,0.6404657933042213,0.7451312447078747
Qwen2.5 32B,false premise,KUQ/False assumptions,NA,0.8691099476439791,0.6240601503759399,0.7264770240700219
Qwen2.5 32B,false premise,QAQA,NA,0.8301886792452831,0.4631578947368421,0.5945945945945946
Qwen2.5 32B,stale,CoCoNot/Temporal,NA,1.0,0.7297297297297297,0.84375
Qwen2.5 32B,stale,FreshQA,NA,0.31896551724137934,0.7872340425531915,0.4539877300613497
Qwen2.5 32B,subjective,CoCoNot/Humanizing,NA,1.0,0.8292682926829268,0.9066666666666666
Qwen2.5 32B,subjective,CoCoNot/Subjective,NA,1.0,0.7066666666666667,0.828125
Qwen2.5 32B,subjective,KUQ/Controversial,NA,0.8602620087336245,0.5845697329376854,0.696113074204947
Qwen2.5 32B,subjective,MoralChoice,NA,0.978021978021978,0.26176470588235295,0.41299303944315546
Qwen2.5 32B,underspecified context,ALCUNA,NA,0.8244620611551529,0.8406466512702079,0.8324757004002287
Qwen2.5 32B,underspecified context,BB/Disambiguate,NA,0.4652777777777778,0.8933333333333333,0.6118721461187214
Qwen2.5 32B,underspecified context,BBQ,NA,0.9651627641347801,0.9505061867266592,0.9577784074808727
Qwen2.5 32B,underspecified context,GPQA-Diamond,NA,1.0,0.65,0.7878787878787878
Qwen2.5 32B,underspecified context,GSM8K,NA,1.0,0.9447650453421269,0.9715981348028826
Qwen2.5 32B,underspecified context,MMLU History,NA,0.8636363636363636,0.48717948717948717,0.6229508196721312
Qwen2.5 32B,underspecified context,MMLU Math,NA,0.9885057471264368,0.6466165413533834,0.7818181818181819
Qwen2.5 32B,underspecified context,MediQ,NA,0.9539951573849879,0.27963094393186655,0.43249176728869376
Qwen2.5 32B,underspecified context,Musique,NA,0.766042780748663,0.8708206686930091,0.8150782361308677
Qwen2.5 32B,underspecified context,QASPER,NA,0.2627986348122867,0.9746835443037974,0.41397849462365593
Qwen2.5 32B,underspecified context,SQuAD 2.0,NA,0.9581529581529582,0.7498588368153586,0.8413050364269876
Qwen2.5 32B,underspecified context,UMWP,NA,0.9914456800684346,0.6622857142857143,0.7941075710859884
Qwen2.5 32B,underspecified context,WorldSense,NA,0.7727272727272727,0.7476851851851852,0.76
Qwen2.5 32B,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.9591836734693877,0.9791666666666666
Qwen2.5 32B,underspecified intent,KUQ/Ambiguous,NA,0.6918032786885245,0.6986754966887417,0.6952224052718287
Qwen2.5 32B,underspecified intent,SituatedQA/Geo,NA,0.47804878048780486,0.7596899224806202,0.5868263473053892
S1.1 32B,answer unknown,BB/Known unknowns,NA,0.9333333333333333,0.6086956521739131,0.7368421052631579
S1.1 32B,answer unknown,CoCoNot/Unknowns,NA,1.0,0.6268656716417911,0.7706422018348624
S1.1 32B,answer unknown,CoCoNot/Unsupported,NA,0.972972972972973,0.6,0.7422680412371134
S1.1 32B,answer unknown,KUQ/Future unknowns,NA,0.9576719576719577,0.5552147239263804,0.7029126213592233
S1.1 32B,answer unknown,KUQ/Unsolved problems,NA,0.9539473684210527,0.6170212765957447,0.7493540051679587
S1.1 32B,false premise,CoCoNot/False presumptions,NA,0.9814814814814815,0.6385542168674698,0.7737226277372263
S1.1 32B,false premise,FalseQA,NA,0.9488054607508533,0.40465793304221254,0.5673469387755102
S1.1 32B,false premise,KUQ/False assumptions,NA,0.9612403100775194,0.46616541353383456,0.6278481012658228
S1.1 32B,false premise,QAQA,NA,0.8608695652173913,0.3473684210526316,0.495
S1.1 32B,stale,CoCoNot/Temporal,NA,1.0,0.5135135135135135,0.6785714285714286
S1.1 32B,stale,FreshQA,NA,0.47368421052631576,0.19148936170212766,0.2727272727272727
S1.1 32B,subjective,CoCoNot/Humanizing,NA,1.0,0.45121951219512196,0.6218487394957983
S1.1 32B,subjective,CoCoNot/Subjective,NA,1.0,0.26666666666666666,0.42105263157894735
S1.1 32B,subjective,KUQ/Controversial,NA,0.9552238805970149,0.3798219584569733,0.5435244161358811
S1.1 32B,subjective,MoralChoice,NA,0.9770992366412213,0.18823529411764706,0.3156596794081381
S1.1 32B,underspecified context,ALCUNA,NA,0.8640776699029126,0.5138568129330254,0.6444605358435916
S1.1 32B,underspecified context,BB/Disambiguate,NA,0.7258064516129032,0.6,0.656934306569343
S1.1 32B,underspecified context,BBQ,NA,0.996316758747698,0.3042744656917885,0.46617837139164153
S1.1 32B,underspecified context,GPQA-Diamond,NA,1.0,0.25,0.4
S1.1 32B,underspecified context,GSM8K,NA,0.9971098265895953,0.28441879637262985,0.44259140474663244
S1.1 32B,underspecified context,MMLU History,NA,1.0,0.05128205128205128,0.0975609756097561
S1.1 32B,underspecified context,MMLU Math,NA,0.9411764705882353,0.12030075187969924,0.21333333333333335
S1.1 32B,underspecified context,MediQ,NA,0.9736842105263158,0.0262597586941093,0.05114029025570145
S1.1 32B,underspecified context,Musique,NA,0.870722433460076,0.5220364741641338,0.6527315914489311
S1.1 32B,underspecified context,QASPER,NA,0.2803030303030303,0.9367088607594937,0.4314868804664723
S1.1 32B,underspecified context,SQuAD 2.0,NA,0.9748743718592965,0.5477131564088086,0.7013738250180767
S1.1 32B,underspecified context,UMWP,NA,0.9982905982905983,0.33371428571428574,0.5002141327623126
S1.1 32B,underspecified context,WorldSense,NA,0.9065817409766455,0.9884259259259259,0.9457364341085271
S1.1 32B,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.5714285714285714,0.7272727272727273
S1.1 32B,underspecified intent,KUQ/Ambiguous,NA,0.8987341772151899,0.47019867549668876,0.6173913043478261
S1.1 32B,underspecified intent,SituatedQA/Geo,NA,0.7843137254901961,0.31007751937984496,0.4444444444444444
TinyLlamaChat,underspecified context,GSM8K,NA,0.9592875318066157,0.3107996702390767,0.46948941469489414
TinyLlamaChat,underspecified context,MMLU History,NA,0.6923076923076923,0.23076923076923078,0.34615384615384615
TinyLlamaChat,underspecified context,MMLU Math,NA,0.8888888888888888,0.18045112781954886,0.3
o1,answer unknown,BB/Known unknowns,NA,0.9583333333333334,1.0,0.9787234042553191
o1,answer unknown,CoCoNot/Unknowns,NA,1.0,1.0,1.0
o1,answer unknown,CoCoNot/Unsupported,NA,1.0,0.8583333333333333,0.9237668161434978
o1,answer unknown,KUQ/Future unknowns,NA,0.9434782608695652,0.6656441717791411,0.7805755395683454
o1,answer unknown,KUQ/Unsolved problems,NA,0.9085714285714286,0.676595744680851,0.775609756097561
o1,false premise,CoCoNot/False presumptions,NA,0.9125,0.8795180722891566,0.8957055214723927
o1,false premise,FalseQA,NA,0.849906191369606,0.6593886462882096,0.7426229508196721
o1,false premise,KUQ/False assumptions,NA,0.948051948051948,0.5488721804511278,0.6952380952380952
o1,false premise,QAQA,NA,0.883495145631068,0.6385964912280702,0.7413441955193483
o1,stale,CoCoNot/Temporal,NA,1.0,0.7567567567567568,0.8615384615384616
o1,stale,FreshQA,NA,0.53125,0.3617021276595745,0.43037974683544306
o1,subjective,CoCoNot/Humanizing,NA,1.0,0.9634146341463414,0.9813664596273292
o1,subjective,CoCoNot/Subjective,NA,1.0,0.7866666666666666,0.8805970149253731
o1,subjective,KUQ/Controversial,NA,0.922077922077922,0.6320474777448071,0.75
o1,subjective,MoralChoice,NA,0.9850746268656716,0.2911764705882353,0.44948921679909193
o1,underspecified context,ALCUNA,NA,0.8596819457436857,0.5306004618937644,0.6561942163513032
o1,underspecified context,BB/Disambiguate,NA,0.4666666666666667,0.84,0.6
o1,underspecified context,BBQ,NA,0.9759519038076152,0.547806524184477,0.7017291066282421
o1,underspecified context,GPQA-Diamond,NA,1.0,0.775,0.8732394366197183
o1,underspecified context,GSM8K,NA,0.9991364421416234,0.953833470733718,0.9759595107549557
o1,underspecified context,MMLU History,NA,1.0,0.4358974358974359,0.6071428571428571
o1,underspecified context,MMLU Math,NA,0.9893617021276596,0.6992481203007519,0.8193832599118943
o1,underspecified context,MediQ,NA,0.9852941176470589,0.09510290986515259,0.17346278317152103
o1,underspecified context,Musique,NA,0.9128571428571428,0.48556231003039513,0.6339285714285714
o1,underspecified context,QASPER,NA,0.1974025974025974,0.9620253164556962,0.3275862068965517
o1,underspecified context,SQuAD 2.0,NA,0.9729944400317713,0.691699604743083,0.8085808580858086
o1,underspecified context,UMWP,NA,0.9985007496251874,0.7611428571428571,0.8638132295719845
o1,underspecified context,WorldSense,NA,0.8924843423799582,0.9895833333333334,0.9385290889132821
o1,underspecified intent,CoCoNot/Incomprehensible,NA,1.0,0.8571428571428571,0.9230769230769231
o1,underspecified intent,KUQ/Ambiguous,NA,0.7905138339920948,0.6622516556291391,0.7207207207207207
o1,underspecified intent,SituatedQA/Geo,NA,0.5903614457831325,0.7596899224806202,0.6644067796610169
o1HighReasoningAPI,underspecified context,GPQA-Diamond,NA,0.9230769230769231,0.6,0.7272727272727273
o1HighReasoningAPI,underspecified context,GSM8K,NA,1.0,0.9546578730420445,0.9768030366933783
o1HighReasoningAPI,underspecified context,MMLU History,NA,1.0,0.358974358974359,0.5283018867924528
o1HighReasoningAPI,underspecified context,MMLU Math,NA,1.0,0.6842105263157895,0.8125
o1LowReasoningAPI,underspecified context,GPQA-Diamond,NA,1.0,0.625,0.7692307692307693
o1LowReasoningAPI,underspecified context,GSM8K,NA,0.9991386735572783,0.9563066776586975,0.9772535804549284
o1LowReasoningAPI,underspecified context,MMLU History,NA,1.0,0.358974358974359,0.5283018867924528
o1LowReasoningAPI,underspecified context,MMLU Math,NA,1.0,0.7142857142857143,0.8333333333333334
