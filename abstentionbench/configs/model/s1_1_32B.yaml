# @package _global_

model_name: S1_1_32B

module:
  _target_: recipe.models.${model_name}
  local_model_path: "/large_experiments/robust_vlm/abstention-bench/huggingface/s1.1-32B"
  temperature: 0.8
  top_p: 0.95
  # 99.9% of non-reasoning models' responses are below 4k tokens;
  # this avoids infinite generation loops in model responses.
  max_tokens: 4000
  max_reasoning_tokens: 4000
  convert_prompt_to_chat: True
  tensor_parallel_size: 8 # Recommended between 4 and max number of available GPUs
  max_model_len: 32768 #Â Context window
  use_system_prompt: False